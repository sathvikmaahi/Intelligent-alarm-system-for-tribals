{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the dataset from the below link\n",
    "https://www.kaggle.com/arbethi/wild-animal-detection-and-alerting-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ImageDataGenerator Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import ImageDataGenerator Library\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Define the parameters /arguments for ImageDataGenerator class\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,\n",
    "        rotation_range=180,zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying ImageDataGenerator functionality to trainset and testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 993 images belonging to 3 classes.\n",
      "Found 353 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#Applying ImageDataGenerator functionality to trainset\n",
    "x_train=train_datagen.flow_from_directory(\n",
    "    directory= r\"F:\\MY PROJECTS\\VEC PROJECTS\\INTELLIGENT ALERT SYSTEM FOR TRIBAL\\Dataset\\train_set\",\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "#Applying ImageDataGenerator functionality to test set\n",
    "x_test=test_datagen.flow_from_directory(\n",
    "    directory= r\"F:\\MY PROJECTS\\VEC PROJECTS\\INTELLIGENT ALERT SYSTEM FOR TRIBAL\\Dataset\\test_set\",\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the model building libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Importing the model building libraries'''\n",
    "#to define linear initializations import Sequential\n",
    "from keras.models import Sequential\n",
    "#To add layers import Dense\n",
    "from keras.layers import Dense\n",
    "# to create a convolution kernel import Convolution2D\n",
    "from keras.layers import Convolution2D\n",
    "# Adding Max pooling Layer\n",
    "from keras.layers import MaxPooling2D\n",
    "# Adding Flatten Layer\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding CNN layers\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),\n",
    "                        activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Max pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Max pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Flatten Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Flatten Layer\n",
    "model.add(Flatten()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Hidden Layers\n",
    "model.add(Dense( kernel_initializer='uniform',activation='relu',units=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 2nd hidden layer\n",
    "model.add(Dense( kernel_initializer='uniform',activation='relu',units=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 3rd hidden layer\n",
    "model.add(Dense( kernel_initializer='uniform',activation='relu',units=60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding output layer\n",
    "model.add(Dense( kernel_initializer='uniform',activation='softmax',units=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the learning process or compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the learning process\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_4236\\4250337181.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(x_train,steps_per_epoch=31,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "31/31 [==============================] - 39s 1s/step - loss: 1.0955 - accuracy: 0.3600 - val_loss: 1.0661 - val_accuracy: 0.4233\n",
      "Epoch 2/15\n",
      "31/31 [==============================] - 16s 510ms/step - loss: 1.0846 - accuracy: 0.3902 - val_loss: 1.0239 - val_accuracy: 0.4545\n",
      "Epoch 3/15\n",
      "31/31 [==============================] - 12s 383ms/step - loss: 1.0652 - accuracy: 0.3902 - val_loss: 0.9569 - val_accuracy: 0.5114\n",
      "Epoch 4/15\n",
      "31/31 [==============================] - 10s 319ms/step - loss: 1.0106 - accuracy: 0.4402 - val_loss: 0.9170 - val_accuracy: 0.5028\n",
      "Epoch 5/15\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 0.9538 - accuracy: 0.5068 - val_loss: 0.9680 - val_accuracy: 0.4886\n",
      "Epoch 6/15\n",
      "31/31 [==============================] - 9s 298ms/step - loss: 0.9450 - accuracy: 0.5151 - val_loss: 0.9176 - val_accuracy: 0.5426\n",
      "Epoch 7/15\n",
      "31/31 [==============================] - 11s 352ms/step - loss: 0.8762 - accuracy: 0.5692 - val_loss: 1.1176 - val_accuracy: 0.4489\n",
      "Epoch 8/15\n",
      "31/31 [==============================] - 10s 315ms/step - loss: 0.9496 - accuracy: 0.5369 - val_loss: 1.1693 - val_accuracy: 0.3750\n",
      "Epoch 9/15\n",
      "31/31 [==============================] - 12s 375ms/step - loss: 0.8870 - accuracy: 0.5525 - val_loss: 0.9092 - val_accuracy: 0.5682\n",
      "Epoch 10/15\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 0.8168 - accuracy: 0.6015 - val_loss: 0.8742 - val_accuracy: 0.5795\n",
      "Epoch 11/15\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 0.8014 - accuracy: 0.6337 - val_loss: 0.9369 - val_accuracy: 0.5653\n",
      "Epoch 12/15\n",
      "31/31 [==============================] - 10s 331ms/step - loss: 0.8014 - accuracy: 0.6243 - val_loss: 0.8758 - val_accuracy: 0.5795\n",
      "Epoch 13/15\n",
      "31/31 [==============================] - 10s 314ms/step - loss: 0.8035 - accuracy: 0.6129 - val_loss: 0.8745 - val_accuracy: 0.6080\n",
      "Epoch 14/15\n",
      "31/31 [==============================] - 9s 303ms/step - loss: 0.7757 - accuracy: 0.6514 - val_loss: 0.8391 - val_accuracy: 0.5767\n",
      "Epoch 15/15\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 0.7480 - accuracy: 0.6597 - val_loss: 1.0252 - val_accuracy: 0.5568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c10c4defd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit_generator(x_train,steps_per_epoch=31,\n",
    "                    epochs=15,\n",
    "                    validation_data=x_test,\n",
    "                    validation_steps=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model \n",
    "model.save('alert.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Human': 0, 'domestic': 1, 'wild': 2}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#import numpy library\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#import load_model method to load our saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "#import image from keras.preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#loading our saved model file\n",
    "model = load_model(r\"F:\\MY PROJECTS\\VEC PROJECTS\\INTELLIGENT ALERT SYSTEM FOR TRIBAL\\Training\\alert.h5\")\n",
    "img = image.load_img(r\"F:\\MY PROJECTS\\VEC PROJECTS\\INTELLIGENT ALERT SYSTEM FOR TRIBAL\\Dataset\\train_set\\domestic\\domestic (28).jpg\",target_size=(64,64))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "#expanding the shape of image to 4 dimensions\n",
    "x = np.expand_dims(x,axis=0)\n",
    "pred = model.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video streaming and alerting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:799: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4236\\2891031939.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mx\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:799: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n"
     ]
    }
   ],
   "source": [
    "#import opencv\n",
    "import cv2\n",
    "#import numpy\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.keras.models  import load_model\n",
    "#import Client from twilio API\n",
    "from twilio.rest import Client\n",
    "#import playsound package\n",
    "from playsound import playsound\n",
    "\n",
    "#Load saved model file using load_model method\n",
    "model = load_model(r'F:\\MY PROJECTS\\VEC PROJECTS\\INTELLIGENT ALERT SYSTEM FOR TRIBAL\\Training\\alert.h5')\n",
    "#To read webcam\n",
    "video = cv2.VideoCapture(0)\n",
    "#Type of classes or names of the labels that we considered\n",
    "name = ['Human','Domestic', 'Wild']\n",
    "#To execute the program repeatedly using while loop   \n",
    "while(1):\n",
    "    success, frame = video.read()\n",
    "    cv2.imwrite(\"image.jpg\",frame)\n",
    "    img = image.load_img(\"image.jpg\",target_size = (64,64))\n",
    "    x  = image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis = 0)\n",
    "    pred = model.predict(x)\n",
    "    p = pred[0]\n",
    "    print(pred)\n",
    "    cv2.putText(frame, \"predicted  class = \"+str(name[p]), (100,100), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "    \n",
    "    pred = model.predict(x)\n",
    "    if pred[0]==2:\n",
    "        #twilio account ssid\n",
    "        account_sid = 'ACbaedc0f433eb384b9fc9957a506c2b99'\n",
    "        #twilo account authentication toke\n",
    "        auth_token = '8d5cd7a614764ea80686686ffb243ca5'\n",
    "        client = Client(account_sid, auth_token)\n",
    "\n",
    "        message = client.messages \\\n",
    "        .create(\n",
    "         body='Danger!. Wild animal is detected, stay alert',\n",
    "         from_=' +15133275578', #the free number of twilio\n",
    "         to='+919100588408')\n",
    "        print(message.sid)\n",
    "        print('Danger!!')\n",
    "        print('Animal Detected')\n",
    "        print ('SMS sent!')\n",
    "        #playsound(r'C:\\Users\\DELL\\Downloads\\Tornado_Siren_II-Delilah-0.mp3')\n",
    "        #break\n",
    "    else:\n",
    "        print(\"No Danger\")\n",
    "       #break\n",
    "    cv2.imshow(\"image\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'): \n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1257: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvNamedWindow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4236\\60533182.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'F:\\MY PROJECTS\\VEC PROJECTS\\INTELLIGENT ALERT SYSTEM FOR TRIBAL\\Training\\alert.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mvideo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamedWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Window\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Human\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Wild aniaml\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"otimher\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.4) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1257: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvNamedWindow'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "#import facevec\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.keras.models  import load_model\n",
    "\n",
    "model = load_model(r'F:\\MY PROJECTS\\VEC PROJECTS\\INTELLIGENT ALERT SYSTEM FOR TRIBAL\\Training\\alert.h5') \n",
    "video = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Window\")\n",
    "name = [\"Human\",\"Wild aniaml\",\"otimher\"]\n",
    "    \n",
    "while(1):\n",
    "    success, frame = video.read()\n",
    "    cv2.imwrite(\"image.jpg\",frame)\n",
    "    img = image.load_img(\"image.jpg\",target_size = (64,64))\n",
    "    x  = image.img_to_array(img)\n",
    "    x = np.expand_dims(x,axis = 0)\n",
    "    pred = model.predict(x)\n",
    "    p = pred[0]\n",
    "    print(pred)\n",
    "    cv2.putText(frame, \"predicted  class = \"+str(name[p]), (100,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1)\n",
    "    cv2.imshow(\"image\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'): \n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
